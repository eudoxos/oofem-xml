{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ae2dad2-4683-4f87-8dcb-2e445552197e",
   "metadata": {},
   "source": [
    "1. compile oofem with -DUSE_TRACE_FIELDS\n",
    "2. adjust paths to the build dir below\n",
    "3. run all the remaining cells to get converted inputs in the `xml` directory\n",
    "4. symlink the `./xml` directory to the `$OOFEM_DIR/tests/xml`, ctest will pick XML tests up automatically\n",
    "\n",
    "What does not work: xfem, contacts (need special records), a few others for unclear reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6de4bc78-ffa2-463d-960a-2fc49b2bf665",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal ctest changing into directory: /home/eudoxos/oofem/build-eigen\n",
      "Test project /home/eudoxos/oofem/build-eigen\n",
      "402/402 Test #392: benchmark_fm_bdam7.oofem.in\u001b[Kn\u001b[KK[Kin\u001b[K[Km.in\u001b[K\n",
      "\u001b[0;32m100% tests passed\u001b[0;0m, 0 tests failed\u001b[0;0m out of 402\n",
      "\n",
      "Total Test time (real) =  17.25 sec\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "OOFEM_DIR='/home/eudoxos/oofem'\n",
    "FIELDS_CSV=os.getcwd()+'/FIELDS.csv'\n",
    "!rm -f {FIELDS_CSV}\n",
    "!OOFEM_TRACE_FIELDS_CSV={FIELDS_CSV} ctest --test-dir {OOFEM_DIR}/build-eigen/ -E '_xml_' --parallel 16  --progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "87c9382b-f67e-41ee-9a4e-3e0615083696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: inconsistent type frcfcmnl.m: int ≠ double\n"
     ]
    }
   ],
   "source": [
    "from rich.pretty import pprint\n",
    "import json\n",
    "ATTRS={}\n",
    "ENUMS={}\n",
    "import csv\n",
    "for ir,(tag,att,T) in enumerate(csv.reader(open(FIELDS_CSV,'r'),delimiter=';')):\n",
    "    tag=tag.lower()\n",
    "    if tag=='~enum~':\n",
    "        if att not in ENUMS: ENUMS[att]=dict([(int(k),v) for k,v in json.loads(T).items()])\n",
    "        continue \n",
    "    if tag not in ATTRS: ATTRS[tag]={}\n",
    "    D=ATTRS[tag]\n",
    "    if att in D:\n",
    "        if T=='flag': continue\n",
    "        if T=='std::string' and D[att].startswith('enum:'): continue\n",
    "        if D[att]=='flag' or (D[att]=='std::string' and T.startswith('enum:')):\n",
    "            D[att]=T\n",
    "            continue\n",
    "        if D[att]!=T: print(f'WARN: inconsistent type {tag}.{att}: {D[att]} ≠ {T}')\n",
    "    else: D[att]=T\n",
    "\n",
    "for CH in ['NODE','ELEMENT','BEAM_ELEMENT','REACTION','LOADLEVEL','EIGVAL','TIME']:\n",
    "    ATTRS['ch_'+CH.lower()]={'tstep':'int','tstepver':'int','number':'int','dofman':'int','dof':'int','irule':'int','gp':'int','component':'int','record':'int','keyword':'std::string','unknown':'std::string','value':'double','eignum':'int','tolerance':'double'}\n",
    "ATTRS['ch_begin_checks']={'tolerance':'double'}\n",
    "# in the test, \"bool vtkexport\" field is false, and exportfields is never read; so we need to delare it manually here\n",
    "ATTRS['xfemstructuremanager']|={'exportfields':'IntArray'}\n",
    "# also only read conditionally, but present in the input file\n",
    "ATTRS['staticstructural']|={'forcescaledofs':'IntArray'}\n",
    "# this record has no parameters, thus does not get exported into the CSV (should be improved)\n",
    "ATTRS['enrfrontextend']={}\n",
    "ATTRS['enrfrontdonothing']={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "37db468d-d731-4e46-91fd-a8c5ba0a1249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pydantic\n",
    "import re\n",
    "from rich.pretty import pprint\n",
    "from typing import List\n",
    "from lxml import etree\n",
    "import csv\n",
    "\n",
    "class InLine(pydantic.BaseModel):\n",
    "    '''One input line, with location information'''\n",
    "    f: str\n",
    "    lineno: int\n",
    "    raw: str\n",
    "    comments: List[str]\n",
    "    toks: List[str]=[]\n",
    "    def loc(self): return f'{self.f}:{self.lineno}'\n",
    "class oofemDialect(csv.Dialect):\n",
    "    'Used to tokenize one line (processes \"...\")'\n",
    "    delimiter=' '\n",
    "    quotechar='\"'\n",
    "    quoting=csv.QUOTE_MINIMAL\n",
    "    skipinitialspace=True\n",
    "    strict=True\n",
    "    lineterminator=''\n",
    "def readOofem(filename):\n",
    "    def fixComment(c):\n",
    "        if c.endswith('-'): c=c+' '\n",
    "        return c.replace('--','—')\n",
    "    file=open(filename,'r')\n",
    "    comment=[]\n",
    "    checkMode=False\n",
    "    lines=[]\n",
    "    checks=[]\n",
    "    checkParams=''\n",
    "    for il,l in enumerate(file.readlines()):\n",
    "        l=l.removesuffix('\\n').replace('\\t',' ')\n",
    "        if (m:=re.fullmatch('#%BEGIN_CHECK%(.*)',l)) and not checkMode :\n",
    "            if checks:\n",
    "                print(f'{filename}:{il+1}: WARN: more than one BEGIN_CHECK blocks, ignoring them.')\n",
    "                comment.append(l[1:])\n",
    "                continue\n",
    "            checkMode=True\n",
    "            rest=m.group(1).strip()\n",
    "            if len(checks)==0: checks.append(InLine(f=filename,lineno=il+1,raw=rest,comments=comment[:]))\n",
    "            else:\n",
    "                # if there are multiple BEGIN_CHECK, concatenate params and comments to the first one\n",
    "                if rest: checks[0].raw+=' '+rest\n",
    "                checks[0].comments+=comment\n",
    "            comment=[]\n",
    "            continue      \n",
    "        if l.startswith('#%END_CHECK%') and checkMode:\n",
    "            checkMode=False\n",
    "            if comment: checks[-1].comments+=comment\n",
    "            comment=[]\n",
    "            continue\n",
    "        if checkMode:\n",
    "            if l=='': continue\n",
    "            if l[0]!='#':\n",
    "                print(f'{filename}:{il+1}: WARN: check line not starting with #: \"{l}\"')\n",
    "                # raise ValueError(f'{filename}:{il+1}: check line not starting with #: \"{l}\"')\n",
    "            elif '//' in l:\n",
    "                a,b=l[1:].split('//',maxsplit=1)\n",
    "                l=a\n",
    "                comment.append(b)\n",
    "            else: l=l[1:]\n",
    "        if m:=re.fullmatch(r'\\s*',l): continue\n",
    "        if m:=re.fullmatch(r'\\s*#+\\s*',l): continue\n",
    "        if m:=re.fullmatch(r'\\s*#+(.*)',l):\n",
    "            comment.append(fixComment(m.group(1).strip()))\n",
    "            continue\n",
    "        if m:=re.fullmatch(r'^(.*)#+(.*)',l):\n",
    "            l=m.group(1)+\"\\n\" # stripped just below\n",
    "            comment.append(fixComment(m.group(2).strip()))\n",
    "        l=l.strip()\n",
    "        if checkMode: checks.append(InLine(f=filename,lineno=il+1,raw='CH_'+l,comments=comment[:]))\n",
    "        else: lines.append(InLine(f=filename,lineno=il+1,raw=l,comments=comment[:]))\n",
    "        comment=[]\n",
    "    # add leftover comments to whatever was last\n",
    "    if comment:\n",
    "        #if not checks or lines[-1].lineno>checks[-1].lineno: lines[-1].comments+=comment\n",
    "        #else: checks[-1].comments+=comment\n",
    "        (lines[-1] if (not checks or lines[-1].lineno>checks[-1].lineno) else checks[-1]).comments+=comment\n",
    "    for LL in lines,checks:\n",
    "        toks=csv.reader([l.raw for l in LL],oofemDialect)\n",
    "        for l,t in zip(LL,toks): l.toks=t\n",
    "    return lines,checks\n",
    "\n",
    "def getNocase(d,k):\n",
    "    if k in d: return d[k]\n",
    "    fromlower=dict([(k.lower(),v) for k,v in d.items()])\n",
    "    return fromlower.get(k.lower(),None)\n",
    "def fixCase(d,k):\n",
    "    if k in d: return k\n",
    "    fromlower=dict([(k.lower(),k) for k in d.keys()])\n",
    "    return fromlower.get(k,None)\n",
    "        \n",
    "\n",
    "def readNextAttr(T,toks,loc,line):\n",
    "    'consume toks, return (attribute name,value)'\n",
    "    attr=toks.pop(0).lower()\n",
    "    def pop0N(n=None,cast=None):\n",
    "        if n is None: n=int(toks.pop(0))\n",
    "        if cast is None: return [toks.pop(0) for i in range(0,n)]\n",
    "        return [cast(toks.pop(0)) for i in range(0,n)]\n",
    "\n",
    "    if T in ('errorcheck','vtkxml') and attr in ('1','2'): return None,None\n",
    "    \n",
    "    if T not in ATTRS: raise ValueError(f'{loc}: {T}: no such record type')\n",
    "    if attr not in ATTRS[T]: raise ValueError(f'{loc}: {T}.{attr}: no such attribute')\n",
    "    aT=ATTRS[T][attr]    \n",
    "        \n",
    "    if aT=='int': return attr,int(toks.pop(0))\n",
    "    elif aT=='flag':\n",
    "        # ATTRS_FLAGS_INT_MAYBE\n",
    "        if len(toks)>0 and toks[0].isdigit():\n",
    "            print(f'{loc}: flag {T}.{attr} followed by an extra numerical field {toks[0]}')\n",
    "            toks.pop(0)\n",
    "        return attr,'' # None\n",
    "    elif aT=='bool':\n",
    "        v=toks.pop(0)\n",
    "        if v not in ('0','1'): raise ValueError(f'{loc}: {T}.{attr}: bool value must be \"0\" or \"1\" (not \"{v}\")')\n",
    "        return attr,v\n",
    "    elif aT=='double': return attr,float(toks.pop(0))\n",
    "    elif aT=='IntArray': return attr,' '.join([str(i) for i in pop0N(cast=int)])\n",
    "    elif aT=='FloatArray': return attr,' '.join([str(i) for i in pop0N(cast=float)])\n",
    "    elif aT=='std::string': return attr,toks.pop(0)\n",
    "    elif aT=='ScalarFunction':\n",
    "        if not toks[0].startswith('$'): return attr,toks.pop(0)\n",
    "        tt=[]\n",
    "        while True:\n",
    "            tt.append(t:=toks.pop(0)) # .removeprefix('$').removesuffix('$'))\n",
    "            if t.endswith('$'): break\n",
    "        return attr,' '.join(tt)\n",
    "    elif aT=='Dictionary':\n",
    "        sz=int(toks.pop(0))\n",
    "        d=dict([(toks.pop(0),toks.pop(0)) for i in range(sz)])\n",
    "        return attr,'; '.join([f'{k} {v}' for k,v in d.items()])\n",
    "    elif aT=='FloatMatrix':\n",
    "        rows,cols=int(toks.pop(0)),int(toks.pop(0))\n",
    "        assert toks[0].startswith('{')\n",
    "        vv=[]\n",
    "        while True:\n",
    "            vv.append((t:=toks.pop(0)).removeprefix('{').removesuffix(';').removesuffix('}'))\n",
    "            if t.endswith('}'): break\n",
    "        vv=[float(v) for v in vv if v!='']\n",
    "        assert len(vv)==rows*cols\n",
    "        # separate rows by semicolon\n",
    "        return attr,'; '.join([' '.join([str(v) for v in vv[row*cols:(row+1)*cols]]) for row in range(rows)])\n",
    "    elif aT=='std::list<Range>':\n",
    "        assert toks[0][0]=='{'\n",
    "        tt=[]\n",
    "        while True:\n",
    "            tt.append(toks.pop(0))\n",
    "            if tt[-1].endswith('}'): break\n",
    "        s=' '.join(tt).removeprefix('{').removesuffix('}')\n",
    "        s=re.sub(r'\\(\\s*([0-9]+)\\s+([0-9]+)\\s*\\)',r'\\1-\\2',s).strip()\n",
    "        s=re.sub(r'\\s+',',',s)\n",
    "        return attr,s\n",
    "    elif aT.startswith('enum:'):\n",
    "        E=ENUMS[aT.removeprefix('enum:')]\n",
    "        return attr,sorted(E[int(toks.pop(0))],key=lambda x: len(x))[0] # return the shortest possible literal for the value\n",
    "    else: raise ValueError(f'{loc}: {T}.{attr} has unhandled type {aT=}.\\n{toks}')\n",
    "    \n",
    "def readInstance(line,optionalT=None,T=None,forceT=None,hasId=False,dropId=False):\n",
    "    # pprint(line.toks)\n",
    "    # print(line)\n",
    "    ret={'_c':line.comments,'_SUB':{}}\n",
    "    toks=line.toks[:]\n",
    "    if optionalT:\n",
    "        if toks[0].lower()==optionalT.lower(): toks.pop(0)\n",
    "    if T is None: T=toks.pop(0)\n",
    "    if forceT is not None: ret['_T'],ret['type']=forceT,T\n",
    "    else: ret['_T']=T\n",
    "    if hasId: ret['_id']=int(toks.pop(0))\n",
    "    elif dropId and len(toks)>0 and re.match(r'\\s*[0-9]\\s*',toks[0]): toks.pop(0)\n",
    "    while toks:\n",
    "        # print(toks)\n",
    "        try: k,v=readNextAttr(T.lower(),toks,loc=line.loc(),line=line)\n",
    "        except BaseException as e: raise ValueError(f'{line.loc()}: error reading attribute: {str(e)}')\n",
    "        # ignored attribute (used for nonsense such as 'errorcheck 1'\n",
    "        if k is None: continue\n",
    "        # print(f'{k=} {v=}')\n",
    "        ret[k]=v\n",
    "    return ret\n",
    "\n",
    "def readDomain(line):\n",
    "    # pprint(line.toks)\n",
    "    assert len(line.toks)==2, f'Domain must have 2 records (not {len(line.toks)}): {line.toks=}'\n",
    "    assert line.toks[0].lower()=='domain', f'Domain record must start with \"domain\": {line.toks=}'\n",
    "    return {'_c':line.comments,'_T':'Domain','_SUB':{},'domain':line.toks[1].lower()}\n",
    "\n",
    "\n",
    "# pprint(readOofem('../tests/sm/control_switch_1.in'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "632b0a84-7e70-473d-8430-bca6d24b46da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "REC = Enum('REC','''Output Description Analysis Metasteps InitModules ExportModules MPMVariables MPMTerms MPMIntegrals Fields\n",
    "    domains OutputManager domaincompres\n",
    "    Nodes Elements ContactSurfaces CrossSections Materials NonlocalBarriers BoundaryConditions InitialConditions LoadTimeFunctions Sets\n",
    "    XFemManager EnrichmentItems enrichmentfunction enrichmentgeometry EnrichmentFront propagationlaw\n",
    "    checks'''.split())\n",
    "XML_SHOW_EMPTY=set([REC.InitialConditions,REC.BoundaryConditions,REC.CrossSections,REC.Materials,REC.Nodes,REC.Elements])\n",
    "# TODO: xfem\n",
    "#    - xfemmanager enrichmentfunction geometry enrichmentitem enrichmentfront propagationlaw cracknucleation fracturemanager failcriterion\n",
    "# enrichmentfunction \n",
    "def parseOofem(filename):\n",
    "    lines,checks=readOofem(filename)\n",
    "    # pprint(checks)\n",
    "    pb={}\n",
    "    # 1. output file record\n",
    "    pb[REC.Output]={'_text':lines.pop(0).raw}\n",
    "    \n",
    "    # 2. job description\n",
    "    pb[REC.Description]={'_text':lines.pop(0).raw}\n",
    "    \n",
    "    # 3. analysis\n",
    "    analysisType=lines[0].toks[0]\n",
    "    pb[REC.Analysis]=ana=readInstance(lines.pop(0),T=None)\n",
    "    # pprint(pb[3])\n",
    "    ana_=ana['_SUB']\n",
    "    ana_[REC.Metasteps]=[readInstance(lines.pop(0),T='~MetaStep~') for i in range(ana.pop('nmsteps',0))]\n",
    "    pb[REC.InitModules]=[readInstance(lines.pop(0)) for i in range(ana.pop('ninitmodules',0))]\n",
    "    pb[REC.ExportModules]=[readInstance(lines.pop(0)) for i in range(ana.pop('nmodules',0))]\n",
    "    # MPM-specific\n",
    "    ana_[REC.MPMVariables]=[readInstance(lines.pop(0)) for i in range(ana.pop('nvariables',0))]\n",
    "    ana_[REC.MPMTerms]=[readInstance(lines.pop(0),hasId=True) for i in range(ana.pop('nterms',0))]\n",
    "    ana_[REC.MPMIntegrals]=[readInstance(lines.pop(0),hasId=True) for i in range(ana.pop('nintegrals',0))]\n",
    "    # fields\n",
    "    ana_[REC.Fields]=[readInstance(lines.pop(0),hasId=False) for i in range(ana.pop('nfields',0))]\n",
    "\n",
    "\n",
    "    setsAfterElements=False\n",
    "\n",
    "    # 4. domains\n",
    "    # handle case-by-case basis\n",
    "    ndomains=1 \n",
    "    #assert lines[0].toks[0].lower()=='domain'\n",
    "    # pb[REC.domains]=[lines.pop(0).toks for i in range(ndomains)]\n",
    "    pb[REC.domains]=[]\n",
    "    for idom in range(ndomains):\n",
    "        pb[REC.domains].append(dom:=readDomain(lines.pop(0)))\n",
    "        dom_=dom['_SUB']\n",
    "        # 5. OutputManager\n",
    "        dom_[REC.OutputManager]=readInstance(lines.pop(0),T='~OutputManager~',optionalT='OutputManager')\n",
    "        # 6. component size record\n",
    "        # dom_[REC.domaincompres]=\n",
    "        dcr=readInstance(lines.pop(0),T='~DomainCompRec~')\n",
    "        # 7. node records\n",
    "        dom_[REC.Nodes]=[readInstance(lines.pop(0),hasId=True) for i in range(dcr.pop('ndofman'))]\n",
    "        # 8. element records\n",
    "        dom_[REC.Elements]=[readInstance(lines.pop(0),hasId=True) for i in range(dcr.pop('nelem'))]\n",
    "        # older syntax order\n",
    "        if lines[0].toks[0].lower()=='set':\n",
    "            dom_[REC.Sets]=[readInstance(lines.pop(0),hasId=True) for i in range(dcr.pop('nset'))]\n",
    "        dom_[REC.ContactSurfaces]=[readInstance(lines.pop(0),hasId=True) for i in range(dcr.pop('ncontactsurf',0))]\n",
    "        # 10. cross sections\n",
    "        dom_[REC.CrossSections]=[readInstance(lines.pop(0),hasId=True) for i in range(dcr.pop('ncrosssect'))]\n",
    "        # 11. material records\n",
    "        dom_[REC.Materials]=[readInstance(lines.pop(0),hasId=True) for i in range(dcr.pop('nmat'))]\n",
    "        # 12. nonlocal barriers\n",
    "        dom_[REC.NonlocalBarriers]=[readInstance(lines.pop(0),hasId=True) for i in range(dcr.pop('nbarrier',0))]\n",
    "        # 13. load/boundary conditions\n",
    "        dom_[REC.BoundaryConditions]=[readInstance(lines.pop(0),hasId=True) for i in range(dcr.pop('nbc'))]\n",
    "        # 14. initial conditions\n",
    "        dom_[REC.InitialConditions]=[readInstance(lines.pop(0),hasId=True) for i in range(dcr.pop('nic'))]\n",
    "        # 15. time function records\n",
    "        dom_[REC.LoadTimeFunctions]=[readInstance(lines.pop(0),hasId=True) for i in range(dcr.pop('nltf'))]\n",
    "        # 9. set records (unless already read previously, in which case dcr no longer has 'nset' as it was poppsed already)\n",
    "        if 'nset' in dcr:\n",
    "            assert REC.Sets not in dom_\n",
    "            dom_[REC.Sets]=[readInstance(lines.pop(0),hasId=True) for i in range(dcr.pop('nset',0))]\n",
    "        nxfemman=dcr.pop('nxfemman',0)\n",
    "        if nxfemman>1: raise RuntimeError(f'Multiple XFemManagers ({nxfemman=}) not supported (never seen in the wild)')\n",
    "        elif nxfemman==1:\n",
    "            dom_[REC.XFemManager]=xfm=readInstance(lines.pop(0),hasId=True,forceT='XFemManager')\n",
    "            xfm['_SUB'][REC.EnrichmentItems]=[]\n",
    "            for j in range(xfm.pop('numberofenrichmentitems',0)):\n",
    "                xfm['_SUB'][REC.EnrichmentItems].append(ei:=readInstance(lines.pop(0),hasId=True)) #for i in range(xfm['numberofenrichmentitems'])]\n",
    "                ei['_SUB'][REC.enrichmentfunction]=ef=readInstance(lines.pop(0),hasId=True,forceT='EnrichmentFunction')\n",
    "                ei['_SUB'][REC.enrichmentgeometry]=eg=readInstance(lines.pop(0),hasId=True,forceT='EnrichmentGeometry')\n",
    "                if ei.pop('enrichmentfront',0)>0:\n",
    "                    # enrichment front has two sides, so two records\n",
    "                    ei['_SUB'][REC.EnrichmentFront]=[readInstance(lines.pop(0),hasId=False,dropId=True) for _ in (0,1)]\n",
    "                if ei.pop('propagationlaw',0)>0: ei['_SUB'][REC.propagationlaw]=readInstance(lines.pop(0),hasId=False,dropId=True,forceT='PropagationLaw')\n",
    "            if xfm.pop('numberofnucleationcriteria',0)>0: raise RuntimeError('XFEMManager.numberofnucleationcriteria: non-zero, but never seen in the wild, thus not yet supported for XML')\n",
    "        dcr.pop('_c'); dcr.pop('_T'); dcr.pop('_SUB');\n",
    "        if len(dcr)>0: raise RuntimeError(f'Unused items in DomainCompRecord: {dcr}.')\n",
    "    if len(lines)>0 and False:\n",
    "        pprint(lines)\n",
    "        raise RuntimeError('leftover lines')\n",
    "    if checks: pb[REC.checks]=[readInstance(checks[0],T='ch_begin_checks')]+[readInstance(l) for l in checks[1:]]\n",
    "\n",
    "    return pb\n",
    "\n",
    "if 0:\n",
    "    # parseOofem('../tests/sm/deepbeamFE2_01.in')\n",
    "    # pprint(p)\n",
    "    import glob\n",
    "    # for f in sorted(glob.glob('../tests/sm/*.in')):\n",
    "    # t=xfemCohesiveZone1.in\n",
    "    t='sm/xfemCrackPropMatForce.in'\n",
    "    #t='benchmark/Tr2shell7XFEM_adaptiveDelam.in'\n",
    "    #t='fm/simpleNonlinearStokes.in'\n",
    "    for f in [f'{OOFEM_DIR}/tests/{t}']:\n",
    "        # print(f)\n",
    "        pb=parseOofem(f)\n",
    "        pprint(pb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f6e0439f-cd13-47f8-8c09-79713d3ddba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "def pb2xml2(pb):\n",
    "    from lxml import etree\n",
    "    root=etree.Element(\"oofem\",version=\"1\")\n",
    "    def app(parent,tag=None,_lastId=0,_text=None,_c=[],_T=None,comments=[],_SUB={},**kw):\n",
    "        if tag is None: tag=_T\n",
    "        # if tag.startswith('~'): tag=kw.pop('_T')\n",
    "        tag={'set':'Set','node':'Node'}.get(tag,tag)\n",
    "        tag=tag.replace('~','')\n",
    "        for c in comments+_c: parent.append(etree.Comment(' '+c+' '))\n",
    "        # if (cc:=comments+_c): parent.append(etree.Comment(' '+'\\n'.join(cc)+' '))\n",
    "        if '_id' in kw:\n",
    "            if (id:=kw.pop('_id'))%5==0 or id!=_lastId+1: kw={'id':id}|kw\n",
    "            _lastId=id\n",
    "        def xmlKw(k):\n",
    "            return {'tstep':'tStep'}.get(k.lower(),k.lower()).replace('/','_').replace('(','_').replace(')','_')\n",
    "        parent.append(e:=etree.Element(tag,**dict([(xmlKw(k),str(v)) for k,v in kw.items()])))\n",
    "        if _text is not None: e.text=_text\n",
    "        for sub,val in _SUB.items():\n",
    "            if isinstance(val,list): # create subgroup\n",
    "                if len(val)==0 and sub not in XML_SHOW_EMPTY: continue\n",
    "                e.append(subgrp:=etree.Element(sub.name))\n",
    "                lastId=0\n",
    "                for v in val: _,lastId=app(subgrp,_lastId=lastId,**v)\n",
    "            else:\n",
    "                app(e,tag=None,**val)    \n",
    "        return e,_lastId\n",
    "    #for k,v in pb.items(): app(root,k.name,v)\n",
    "    #return root\n",
    "    app(root,'Output',**pb[REC.Output])\n",
    "    app(root,'Description',**pb[REC.Description])\n",
    "    # analysis\n",
    "    ana=app(root,tag='Analysis',type=pb[REC.Analysis].pop('_T'),**pb[REC.Analysis])[0]\n",
    "    for dom in pb[REC.domains]:\n",
    "        dom=app(root,tag='Domain',**dom)\n",
    "\n",
    "    for key in [REC.InitModules,REC.ExportModules]:\n",
    "        if len(pb.get(key,[]))==0: continue\n",
    "        root.append(mm:=etree.Element(key.name))\n",
    "        for n in pb[key]:\n",
    "            if n['_T'].lower()=='errorcheck' and (REC.checks in pb):\n",
    "                n|=pb[REC.checks][0]\n",
    "                n['_T']='errorcheck' # lowercase\n",
    "            mod=app(mm,tag=None,**n)[0]\n",
    "            if n['_T'].lower()=='errorcheck':\n",
    "                for c in pb[REC.checks][1:]:\n",
    "                    c['_T']=c['_T'].removeprefix('ch_').removeprefix('CH_').upper()\n",
    "                    app(mod,tag=None,**c)\n",
    "    return root\n",
    "if 0:\n",
    "    pb=parseOofem(f'{OOFEM_DIR}/tests/fm/cbs1.in')\n",
    "    # pprint(pb)\n",
    "    xml=pb2xml2(pb)\n",
    "    print(etree.tostring(xml,pretty_print=True,encoding='utf-8').decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "8fb1bf19-677f-483d-b164-47ab67132dbb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pb2xml(pb):\n",
    "    from lxml import etree\n",
    "    root=etree.Element(\"oofem\",version=\"1\")\n",
    "    def app(parent,tag,_lastId=0,text=None,_c=[],_T=None,comments=[],**kw):\n",
    "        if tag is None: tag=_T\n",
    "        tag={'set':'Set','node':'Node'}.get(tag,tag)\n",
    "        kw.pop('_T',None)\n",
    "        for c in comments+_c: parent.append(etree.Comment(' '+c+' '))\n",
    "        if '_id' in kw:\n",
    "            if (id:=kw.pop('_id'))%5==0 or id!=_lastId+1: kw={'id':id}|kw\n",
    "            _lastId=id\n",
    "        def fixKw(k):\n",
    "            return {'tstep':'tStep'}.get(k.lower(),k.lower()).replace('/','_').replace('(','_').replace(')','_')\n",
    "        kw2=dict([(fixKw(k),str(v)) for k,v in kw.items()])\n",
    "        if 'f(t)' in kw2.keys(): kw2['f_t_']=kw2.pop('f(t)')\n",
    "        parent.append(e:=etree.Element(tag,**kw2))\n",
    "        if text is not None: e.text=text\n",
    "        return e,_lastId\n",
    "    app(root,'Output',text=pb[REC.output])\n",
    "    app(root,'Description',text=pb[REC.jobdesc])\n",
    "    # analysis\n",
    "    ana=app(root,tag='Analysis',type=pb[REC.analysis].pop('_T'),**pb[REC.analysis])[0]\n",
    "    # metasteps\n",
    "    if REC.metasteps in pb and len(pb[REC.metasteps])>0:\n",
    "        ana.append(ms:=etree.Element('Metasteps'))\n",
    "        for n in pb[REC.metasteps]: app(ms,tag='Metastep',**n)\n",
    "    # MPM\n",
    "    if REC.mpmvariables in pb and len(pb[REC.mpmvariables])>0:\n",
    "        for group,key,tag in [('MPMVariables',REC.mpmvariables,'Variable'),('MPMTerms',REC.mpmterms,None),('MPMIntegrals',REC.mpmintegrals,'Integral')]:\n",
    "            ana.append(gr:=etree.Element(group))\n",
    "            lastId=0\n",
    "            for n in pb[key]: _,lastId=app(gr,_lastId=lastId,tag=None,**n)\n",
    "    if REC.fields in pb and len(pb[REC.fields])>0:\n",
    "        ana.append(gr:=etree.Element('Fields'))\n",
    "        for n in pb[REC.fields]: app(gr,tag=None,**n)\n",
    "        \n",
    "    # root.append(domains:=etree.Element('Domains'))\n",
    "    for domRec in pb[REC.domains]:\n",
    "        root.append(dom:=etree.Element('Domain',domain=domRec[1].lower()))\n",
    "        app(dom,'OutputManager',**pb[REC.outputmanager])\n",
    "        for group,key in [('Nodes',REC.nodes),('Elements',REC.elements),('CrossSections',REC.crosssections),('Materials',REC.materials),('NonlocalBarriers',REC.nonlocalbarriers),('BoundaryConditions',REC.boundaryconditions),('InitialConditions',REC.initialconditions),('LoadTimeFunctions',REC.loadtimefunctions),('Sets',REC.sets)]:\n",
    "            if group in ('NonlocalBarriers',) and len(pb[key])==0: continue\n",
    "            dom.append(nodes:=etree.Element(group))\n",
    "            lastId=0\n",
    "            for n in pb[key]: _,lastId=app(nodes,_lastId=lastId,tag=None,**n)\n",
    "            \n",
    "    for group,key in [('InitModules',REC.initmodules),('ExportModules',REC.exportmodules)]:\n",
    "        if len(pb.get(key,[]))==0: continue\n",
    "        root.append(mm:=etree.Element(group))\n",
    "        for n in pb[key]:\n",
    "            if n['_T'].lower()=='errorcheck' and (REC.checks in pb):\n",
    "                n|=pb[REC.checks][0]\n",
    "                n['_T']='errorcheck' # lowercase\n",
    "            mod=app(mm,tag=None,**n)[0]\n",
    "            if n['_T'].lower()=='errorcheck':\n",
    "                for c in pb[REC.checks][1:]:\n",
    "                    c['_T']=c['_T'].removeprefix('ch_').removeprefix('CH_').upper()\n",
    "                    app(mod,tag=None,**c)\n",
    "    return root\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "c18d9759-d3d8-47de-b5a6-d0b97093b82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eudoxos/oofem/tests/sm/lattice3dboundarytruss.in:45: WARN: more than one BEGIN_CHECK blocks, ignoring them.\n",
      "/home/eudoxos/oofem/tests/benchmark/tmsmdssiml/MPS_bench01_tmsm.in → ./xml/benchmark/tmsmdssiml/MPS_bench01_tmsm.xml\n",
      "/home/eudoxos/oofem/tests/benchmark/tmsmdssiml/MPS_bench01_tmsm.in: error:\n",
      "    pop from empty list\n",
      "/home/eudoxos/oofem/tests/benchmark/tmsmdssiml/MPS_bench02_tmsm.in → ./xml/benchmark/tmsmdssiml/MPS_bench02_tmsm.xml\n",
      "/home/eudoxos/oofem/tests/benchmark/tmsmdssiml/MPS_bench02_tmsm.in: error:\n",
      "    pop from empty list\n"
     ]
    }
   ],
   "source": [
    "if 1:\n",
    "    import glob, os, shutil\n",
    "    testDir=f'{OOFEM_DIR}/tests/'\n",
    "    for root0,dirs,files in os.walk(testDir):\n",
    "        #for testDir in ['sm','tm','fm']:\n",
    "        root=root0.removeprefix(testDir)\n",
    "        if root.startswith('xml'): continue\n",
    "        if root.startswith('Testing'): continue\n",
    "        if 'python' in root: continue\n",
    "        dstDir=f'./xml/{root}'\n",
    "        # if root!='mpm': continue\n",
    "        if root.split('/')[0] in ('smmfront','partests','tmcemhyd','fmpfem','tmsm','am'): continue\n",
    "        if '/obsolete' in root: continue\n",
    "        # print(root)\n",
    "        os.makedirs(dstDir,exist_ok=True)\n",
    "        for f0 in sorted(files):\n",
    "            # if not f0.startswith('xfem'): continue\n",
    "            # print(f'{root0}/{f0} → {dstDir}/{f0}')\n",
    "            f=f'{root0}/{f0}'\n",
    "            if 'benchmark/Tr2shell' in f: continue # these 2 are broken (not consumed by ctest, hence fields not traced)\n",
    "            ext=os.path.splitext(f)[1]\n",
    "            # print(f)\n",
    "            # for f in sorted(glob.glob(f'../tests/{testDir}/*')):\n",
    "            # for f in ['../tests/sm/lattice3dboundarytruss.in']:\n",
    "            #if os.path.isdir(f): continue\n",
    "            if ext=='.in':\n",
    "                out=f'{dstDir}/{os.path.basename(f).removesuffix(\".in\")}.xml'\n",
    "                # print(f'{f} → {out}')\n",
    "                try:\n",
    "                    xml=pb2xml2(pb:=parseOofem(f))\n",
    "                    #if xml.find('.//XFEMManagers') is not None:\n",
    "                    #    print('  XFEM not yet supported, skipping...')\n",
    "                    #    continue\n",
    "                    open(out,'wb').write(etree.tostring(xml,pretty_print=True))\n",
    "                except Exception as e:\n",
    "                    print(f'{f} → {out}')\n",
    "                    print(f'{f}: error:\\n    {str(e)}')\n",
    "                    # raise\n",
    "            elif ext in ('.rve','.dat','.t3d') or f0.endswith('.in.0'):\n",
    "                dst=f'{dstDir}/{os.path.basename(f)}'\n",
    "                # print(f'   {f} → {dst}')\n",
    "                shutil.copy(f,dst)\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddbba56-7e07-464e-b08f-dcd008372565",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
